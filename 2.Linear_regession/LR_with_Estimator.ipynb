{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature columns\n",
    "The feature_column module of TensorFlow 2 acts as a bridge between your input data and the model. \n",
    "\n",
    "The input parameters to be used by the estimators for training are passed as feature columns. \n",
    "\n",
    "They are defined in TensorFlow feature_column and specify how the data is interpreted by the model. \n",
    "\n",
    "To create feature columns we will need to call functions from **tensorflow.feature_columns**.\n",
    "\n",
    "There are nine functions available in feature column:\n",
    "\n",
    "    * categorical_column_with_identity: Here each category is one-hot encoded, and thus has a unique identity. This can be used for numeric values only.\n",
    "\n",
    "\n",
    "    * categorical_column_with_vocabulary_file: This is used when the categorical input is a string and the categories are given in a file. The string is first converted to a numeric value and then one-hot encoded.\n",
    "\n",
    "\n",
    "    * categorical_column_with_vocabulary_list: This is used when the categorical input is a string and the categories are explicitly defined in a list. The string is first converted to a numeric value and then one-hot encoded.\n",
    "\n",
    "\n",
    "    * categorical_column_with_hash_bucket: In case the number of categories is very large, and it is not possible to one-hot encode, we use hashing.\n",
    "\n",
    "\n",
    "    * crossed_column: When we want to use two columns combined as one feature, for example, in the case of geolocation-based data it makes sense to combine longitude and latitude values as one feature.\n",
    "\n",
    "\n",
    "    * numeric_column: Used when the feature is a numeric, it can be a single value or even a matrix.\n",
    "\n",
    "\n",
    "    * indicator_column: We do not use this directly. Instead, it is used with the categorical column, but only when the number of categories is limited and can be represented as one-hot encoded.\n",
    "\n",
    "\n",
    "    * embedding_column: We do not use this directly. Instead, it is used with the categorical column, but only when the number of categories is very large and cannot be represented as one-hot encoded.\n",
    "\n",
    "\n",
    "    * bucketized_column: This is used when, instead of a specific numeric value, we split the data into different categories depending upon its value.\n",
    "\n",
    "\n",
    "\n",
    "The first six functions inherit from the Categorical Column class, the next three inherit from the Dense Column class, and the last one inherits from both classes. In the following example we will use numeric_column and categorical_column_with_vocabulary_list functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import feature_column as fc\n",
    "\n",
    "numeric_column = fc.numeric_column\n",
    "categorical_column_with_vocabulary_list = fc.categorical_column_with_vocabulary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "featcols = [\n",
    "tf.feature_column.numeric_column(\"area\"),\n",
    "tf.feature_column.categorical_column_with_vocabulary_list(\"type\",[\"bungalow\",\"apartment\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    features = {\"area\":[1000,2000,4000,1000,2000,4000],\n",
    "    \"type\":[\"bungalow\",\"bungalow\",\"house\",\n",
    "         \"apartment\",\"apartment\",\"apartment\"]}\n",
    "    labels = [ 500 , 1000 , 1500 , 700 , 1300 , 1900 ]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/vm/vq630f6x7dx4shwqz6hskm_m0000gn/T/tmp0xq_84to\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/vm/vq630f6x7dx4shwqz6hskm_m0000gn/T/tmp0xq_84to', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/vm/vq630f6x7dx4shwqz6hskm_m0000gn/T/tmp0xq_84to/model.ckpt.\n",
      "INFO:tensorflow:loss = 1548333.4, step = 0\n",
      "INFO:tensorflow:global_step/sec: 558.709\n",
      "INFO:tensorflow:loss = 54075.324, step = 100 (0.180 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/vm/vq630f6x7dx4shwqz6hskm_m0000gn/T/tmp0xq_84to/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 53623.418.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x13929f990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.estimator.LinearRegressor(featcols)\n",
    "model.train(train_input_fn,steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn():\n",
    "    features = {\"area\" : [1500,1800],\n",
    "              \"type\" : ['house','apt']}\n",
    "    return features\n",
    "\n",
    "prediction = model.predict(predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/vm/vq630f6x7dx4shwqz6hskm_m0000gn/T/tmp0xq_84to/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'predictions': array([692.7829], dtype=float32)}\n",
      "{'predictions': array([830.9035], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(next(prediction))\n",
    "print(next(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
